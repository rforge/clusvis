{
    "collab_server" : "",
    "contents" : "#include <iostream>\n#include <iomanip>\n#include <RcppArmadillo.h>\n#include <Rcpp.h>\n\nusing namespace std;\nusing namespace arma;\nusing namespace Rcpp;\n\n\nMat<double> convertVecToMat(const Col<double>&  vec, const int  dim){\n  Mat<double> mat(dim, dim);\n  mat.zeros(dim, dim);\n  int cp=0;\n  for (int j=0; j<dim; j++){\n    for (int i=j; i<dim; i++){\n      mat(i,j) = vec(cp);\n      cp++;\n    }\n  }\n  return mat;\n}\n\nRow<double> convertMatToVec(const Mat<double>  mat){\n  int dim = ((mat.n_rows - 1) * mat.n_rows) /2;\n  Row<double> out(dim);\n  out.zeros(dim);\n  int cp=0;\n  for (int j=0; j<mat.n_cols; j++){\n    for (int i=j; i<(mat.n_rows-1); i++){\n      out(cp) = mat(i,j);\n      cp++;\n    }\n  }\n  return out;\n}\n\nMat<double> phiinvall(const Mat<double>& loguref, const Mat<double> mumat){\n  const Mat<double> mumatinv = inv(mumat);\n  Row<double> tmp = 0.5 * trans(mumatinv * sum(mumat % mumat, 1));\n  Mat<double> out = loguref * trans(mumatinv);\n  out.each_row() += tmp;\n  return out;\n}\n\nRow<double> gradphiinvhh(const Row<double> yi, const Mat<double>& mumatupref, const int h){\n  Row<double> out = yi*0;\n  for (int l=0; l<=h; l++)\n    out(l) = (mumatupref(h,l) - yi(l)) /mumatupref(h,h);\n\n  return out ;\n}\n\nvector< Mat<double> > computegradPhiInv(const Row<double> yi, const Mat<double>& mumatupref){\n  vector< Mat<double> > listgradphiinvhkl;\n  const int dim=mumatupref.n_cols;\n  listgradphiinvhkl.resize(dim);\n  for (int h=0; h<dim; h++){\n    listgradphiinvhkl[h] = zeros<mat>(dim + 1, dim);\n    listgradphiinvhkl[h].row(h) = gradphiinvhh(yi, mumatupref, h);\n    if (h>0){\n      Mat<double> add=zeros<mat>(dim + 1, dim);\n      for (int hp=0; hp<h; hp++)\n        add += listgradphiinvhkl[hp] * mumatupref(h, hp);\n\n      listgradphiinvhkl[h] -= (add/mumatupref(h,h));\n    }\n  }\n  return listgradphiinvhkl;\n}\n\nMat<double> gradl1ind(const Row<double> w, const Row<double> yi, const Mat<double>& mumatupref){\n  const int dim = mumatupref.n_cols;\n  Mat<double> out=zeros<mat>(dim + 1, dim);\n  vector< Mat<double> > gradphiinv = computegradPhiInv(yi, mumatupref);\n  Mat<double> delta=zeros<mat>(dim + 1, dim);\n  for (int k=0; k<=dim; k++)\n    delta.row(k) = (mumatupref.row(k) - yi) * w(k);\n\n  // for (int l=0; l<dim; l++)\n  //   delta.col(l) = delta.col(l) * w(l);\n\n  Row<double> sumdelta = sum(delta, 0);\n\n  for (int h=0; h<dim; h++)\n    out += gradphiinv[h] * sumdelta(h);\n\n  for (int k=0; k<dim; k++){\n    for(int l=0; l<=k; l++){\n      out(k,l) -= delta(k,l) ;\n    }\n  }\n  return out;\n}\n\ndouble Sign(const double number){\n  double out = 1.0;\n  if (number < 0) out= -1.0;\n  return out;\n}\n\nRow<double> computeGradient(const Col<double>& param, const Mat<double>& loguref, const Mat<double>& tikref){\n  Mat<double> mumat = convertVecToMat(param, loguref.n_cols);\n  Mat<double> y = phiinvall(loguref, mumat);\n  Mat<double> grr = zeros(mumat.n_rows + 1, mumat.n_cols);\n  grr.zeros(mumat.n_rows+1, mumat.n_cols);\n  for (int k=0; k<grr.n_cols; k++)\n     grr(k,k) = - (Sign(mumat(k,k))/mumat(k,k)) * (loguref.n_rows);\n\n  Mat<double> mumatup=resize(mumat, mumat.n_rows + 1, mumat.n_cols);\n  mumatup.row(mumatup.n_rows -1) = 0 * mumatup.row(mumatup.n_rows -1);\n  Mat<double>& mumatupref = mumatup;\n  for (int i=0; i<(loguref.n_rows); i++)\n    grr += gradl1ind(tikref.row(i), y.row(i), mumatupref);\n\n  return convertMatToVec(grr);\n}\n\ndouble computeCompleteLogLikelihood(const Col<double>& param, const vector<double>& prop, const Mat<double>& loguref, const Mat<double>& tikref){\n  Mat<double> mumat = convertVecToMat(param, loguref.n_cols);\n  Mat<double> y = phiinvall(loguref, mumat);\n  Mat<double> mumatup=resize(mumat, mumat.n_rows + 1, mumat.n_cols);\n  mumatup.row(mumatup.n_rows -1) = 0 * mumatup.row(mumatup.n_rows -1);\n  double out=0;\n  double d=y.n_cols;\n  for (int k=0; k<=d; k++){\n    Mat<double> tmp = (y.each_row() - mumatup.row(k));\n    out+= (-0.5) * sum(sum(tmp % tmp, 1) % tikref.col(k)) + sum(tikref.col(k)) * log(prop[k]) - sum(tikref.col(k))*(d)*log(sqrt(2*M_PI));\n  }\n  for (int k=0; k<d; k++)\n    out -= sum(log(abs(mumat(k,k)))) * (loguref.n_rows);\n  out -= sum(sum(loguref));\n  return out;\n}\n\n//[[Rcpp::export]]\nNumericVector  computeGradientCPP(NumericVector Rparam, NumericVector Rprop, NumericMatrix Rlogu, NumericMatrix Rtik){\n  Mat<double> logu(Rlogu.nrow(), Rlogu.ncol());\n  logu= as<mat>(Rlogu);\n  Mat<double>& loguref = logu;\n  Mat<double> tik(Rtik.nrow(), Rtik.ncol());\n  tik= as<mat>(Rtik);\n  Mat<double>& tikref= tik;\n  Col<double> param(Rparam.size());\n  param= as<vec>(Rparam);\n  Col<double>& paramref = param;\n  Row<double> out=computeGradient(paramref, loguref, tikref);\n  return wrap(out);\n}\n\n//[[Rcpp::export]]\nNumericVector  computeLikelihoodCPP(NumericVector Rparam, NumericVector Rprop, NumericMatrix Rlogu, NumericMatrix Rtik){\n  Col<double> param(Rparam.size());\n  param= as<vec>(Rparam);\n  Col<double>& paramref = param;\n\n\n  vector< double > prop(Rprop.size());\n  for (int j=0; j<prop.size(); j++) prop[j] = Rprop[j];\n  vector<double>& propref = prop;\n\n  Mat<double> logu(Rlogu.nrow(), Rlogu.ncol());\n  logu= as<mat>(Rlogu);\n  Mat<double>& loguref = logu;\n\n  Mat<double> tik(Rtik.nrow(), Rtik.ncol());\n  tik= as<mat>(Rtik);\n  Mat<double>& tikref= tik;\n\n  double out=computeCompleteLogLikelihood(paramref, propref, loguref, tikref);\n  return wrap(out);\n}\n",
    "created" : 1498477599550.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "148769454",
    "id" : "D9882593",
    "lastKnownWriteTime" : 1492786985,
    "last_content_update" : 1492786985,
    "path" : "~/Documents/recherche/visualisation/clusvis/pkg/src/clusvis.cpp",
    "project_path" : "pkg/src/clusvis.cpp",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "cpp"
}