{
    "collab_server" : "",
    "contents" : "\n##' Model-based visualization of model-based clustering.\n##'\n##' To do\n##'\n##' \\tabular{ll}{\n##'   Package: \\tab ClusVis\\cr\n##'   Type: \\tab Package\\cr\n##'   Version: \\tab 0.1.1\\cr\n##'   Date: \\tab 2017-04-03\\cr\n##'   License: \\tab GPL-2\\cr\n##'   LazyLoad: \\tab yes\\cr\n##' }\n##'\n##' The main function for parameter inference is \\link{clusvis}.\n##' However, specific functions for parameter inference  \\link{clusvisMixmod} are implemented to deal with model-based clustering done with R packages Rmixmod and Rmixcomp respectively.\n##' After parameter inference, visualization is done with function \\link{plotDensityClusVisu}.\n##'\n##'\n##' @name ClusVis-package\n##' @aliases ClusVis\n##' @rdname ClusVis-package\n##' @docType package\n##' @keywords package\n##' @useDynLib ClusVis\n##' @author Marbac, M., Biernacki, C., and Vandewalle, V.\n##' @import Rcpp\n##' @import RcppArmadillo\n##' @import MASS\n##' @import parallel\n##' @import mgcv\n##' @import mvtnorm\n##' @import Rmixmod\n##'\n##' @examples\n##' ### Categorical data clustering\n##' # Package loading\n##' require(Rmixmod)\n##'  \n##' # Data loading (categorical data)\n##' data(birds)\n##'\n##' # Model-based clustering with 3 components\n##' resmixmod <- mixmodCluster(birds, 3)\n##'\n##' # Inference of the parameters used for results visualization (general approach)\n##' # Probabilities of classification are not sampled from the model parameter,\n##' # but observed probabilities of classification are used for parameter estimation\n##' resvisu <- clusvis(log(resmixmod@bestResult@proba),\n##'                    resmixmod@bestResult@parameters@proportions)\n##'\n##' # Inference of the parameters used for results visualization\n##' # (specific for Rmixmod results)\n##' # It is better because probabilities of classification are generated\n##' # by using the model parameters\n##' resvisu <- clusvisMixmod(resmixmod)\n##'\n##' # Component interpretation graph\n##' plotDensityClusVisu(resvisu)\n##'\n##' # Scatter-plot of the observation memberships\n##' plotDensityClusVisu(resvisu,  add.obs = TRUE)\nNULL\n\n\n###################################################################################\n##' This function estimates the parameters used for visualization\n##'\n##'\n##' @param logtik.estim matrix. It contains the probabilities of classification used for parameter inference (should be sampled from the model parameter or computed from the observations).\n##' @param prop vector. It contains the class proportions (by default, classes have same proportion).\n##' @param logtik.obs   matrix. It contains the probabilities of classification of the clustered sample. If missing, logtik.estim is used.\n##' @param maxit numeric. It limits the number of iterations for the Quasi-Newton algorithm (default 1000).\n##' @param nbrandomInit numeric. It defines the number of random initialization of the Quasi-Newton algorithm.\n##' @param nbcpu numeric. It specifies the number of CPU (only for linux)\n##'\n##' @return Returns a list\n##' @examples\n##' # Package loading\n##' require(Rmixmod)\n##'  \n##' # Data loading (categorical data)\n##' data(birds)\n##'\n##' # Model-based clustering with 3 components\n##' resmixmod <- mixmodCluster(birds, 3)\n##'\n##' # Inference of the parameters used for results visualization (general approach)\n##' # Probabilities of classification are not sampled from the model parameter,\n##' # but observed probabilities of classification are used for parameter estimation\n##' resvisu <- clusvis(log(resmixmod@bestResult@proba),\n##'                    resmixmod@bestResult@parameters@proportions)\n##\n##' @export\n##'\n##'\nclusvis <- function(logtik.estim,\n                    prop=rep(1/ncol(logtik.estim), ncol(logtik.estim)),\n                    logtik.obs=NULL,\n                    maxit=10**3,\n                    nbrandomInit=12,\n                    nbcpu=3){\n  if (any(logtik.estim == -Inf)) logtik.estim <- logtik.estim[which(rowSums(logtik.estim == -Inf) ==0),]\n  if (is.null(logtik.obs))   logtik.obs <- logtik.estim\n  out <- list()\n  out$prop <- prop\n  out$startvec <- smartInit(logtik.estim, out$prop)\n  out$startmat <- convertmuVecToMat(out$startvec,  ncol(logtik.estim) - 1 )\n  loguref <- sweep(logtik.estim, 1, logtik.estim[,ncol(logtik.estim)], \"-\")[, -ncol(logtik.estim), drop=FALSE]\n  logurefweighted <- sweep(loguref, 2, log(out$prop[length(out$prop)]) - log(out$prop[-length(out$prop)]), \"+\")\n  if (length(prop)==2){\n    out$centers <- out$startvec\n  }else{\n    allinit <- list(out$startvec)\n    if (nbrandomInit>1)\n      allinit <- c(allinit, lapply(1:(nbrandomInit-1), function(i) runif(length(out$startvec), max = 25)) )\n    allresults <- mclapply(allinit,\n                           function(start)\n                             optim(par = out$startvec,\n                                   fn = computeLikelihoodCPP,\n                                   gr = computeGradientCPP,\n                                   control = list(maxit=maxit, fnscale=-1),\n                                   Rprop=prop,\n                                   Rlogu=logurefweighted,\n                                   Rtik=exp(logtik.estim),\n                                   method=\"BFGS\"), mc.cores = nbcpu)\n    values <- sapply(allresults, function(i) i$value)\n    out$optim <- allresults[[which.max(values)]]\n    values <- round(values, 2)\n    out$nbbest <- sum(values == max(values))\n    out$centers <- convertmuVecToMat(out$optim$par, ncol(logtik.estim) - 1 )\n    out$allresults <- allresults\n  }\n  out$logtik.obs <- logtik.obs\n  out$dist <- as.matrix(dist(out$centers))\n  out$partition <- list(hard= apply(logtik.obs, 1, which.max), fuzzy= exp(logtik.obs))\n  loguobs <- sweep(logtik.obs, 1, logtik.obs[,ncol(logtik.obs)], \"-\")[, -ncol(logtik.obs), drop=FALSE]\n  loguobsweighted <- sweep(loguobs, 2, log(out$prop[length(out$prop)]) - log(out$prop[-length(out$prop)]), \"+\")\n  out$y <- phiinvall(loguobsweighted, out$centers)\n  g <- as.numeric(t(out$centers) %*% out$prop)\n  out$centers <- sweep(out$centers, 2, g, \"-\")\n  tmp <- eigen(t(out$centers) %*% diag(out$prop) %*% out$centers)\n  out$centers <- out$centers %*% tmp$vectors\n  out$y <- sweep(out$y, 2, g, \"-\") %*% tmp$vectors\n  out$inertia <- tmp$values\n  out$logtik.obs <- logtik.obs\n # out$modes <- modesSearch(out$prop, out$centers)\n  tmp <- rlogtikvisu(out, nrow(logtik.estim))\n  out$EM <- -sum(exp(logtik.estim) * logtik.estim)/(log(ncol(tmp)) * nrow(tmp))\n  out$EV <- -sum(exp(tmp) * tmp) / (log(ncol(tmp)) * nrow(logtik.estim))\n  tmp2 <- rlogtikvisu(out, nrow(logtik.estim), 1:(length(out$prop)-1))\n  out$EVtot <- -sum(exp(tmp2) * tmp2) / (log(ncol(tmp2)) * nrow(logtik.estim))\n  return(out)\n}\n\n\n\nrlogtikvisu <- function(out, sample.size, dim=c(1,2)){\n  z <- sample(1:length(out$prop), sample.size, replace=TRUE, prob = out$prop)\n  x <- sapply(dim, function(d) rnorm(sample.size, out$centers[z,d], 1))\n  logprob <- sapply(1:length(out$prop),\n                    function(z) rowSums(sapply(dim, function(d) dnorm(x[,d], out$centers[z,d], 1, log=TRUE))) + log(out$prop[z]))\n  logprob <- sweep(logprob, 1, apply(logprob, 1, max), \"-\")\n  sweep(logprob, 1, log(rowSums(exp(logprob))), \"-\")\n}\n",
    "created" : 1498227688361.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1350248159",
    "id" : "44C1F5",
    "lastKnownWriteTime" : 1498229290,
    "last_content_update" : 1498229290273,
    "path" : "~/Documents/recherche/visualisation/clusvis/pkg/R/clusvis.R",
    "project_path" : "pkg/R/clusvis.R",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}